{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import rdkit\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import mean\n",
    "from numpy import interp\n",
    "from matplotlib import pyplot\n",
    "from numpy.random import randint\n",
    "from sklearn.metrics import roc_curve\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingRandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(outer_true,outer_pred,outer_prob):\n",
    "    \n",
    "    # print statement and list elements are appended into single arrays for convenience\n",
    "    y_true = np.hstack(outer_true)\n",
    "    y_pred = np.hstack(outer_pred)\n",
    "    y_prob = np.vstack(outer_prob)[:,-1]\n",
    "    \n",
    "    \n",
    "    # confusion matrix is printed using built in functions\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "#     print(conf_matrix)\n",
    "    \n",
    "    \n",
    "    # classification report and other metrics are generated\n",
    "#     print(classification_report(y_true, y_pred))\n",
    "#     print('balanced_acc_score:\\t{}\\n'.format(balanced_accuracy_score(y_true, y_pred)))\n",
    "#     print('matthews_corr_coef:\\t{}\\n'.format(matthews_corrcoef(y_true, y_pred)))\n",
    "\n",
    "\n",
    "    # Sensitivity and specificity are calculated from the confusion matrix and are then printed\n",
    "    Sensitivity = conf_matrix[0,0]/(conf_matrix[0,0]+conf_matrix[0,1])\n",
    "    Specificity = conf_matrix[1,1]/(conf_matrix[1,0]+conf_matrix[1,1]) \n",
    "#     print('Sensitivity:\\t{}\\n'.format(Sensitivity))\n",
    "#     print('Specificity:\\t{}\\n'.format(Specificity))\n",
    "\n",
    "    \n",
    "    # AUC is calculated from the probabilities and the true y values\n",
    "    AUC_base_model = roc_auc_score(y_true, y_prob)\n",
    "#     print(\"AUC-ROC:\\t{}\\n\".format(AUC_base_model))\n",
    "    \n",
    "    # calculate and print the ROC from the aggregated (i.e. stacked) outer predictions and plot the graph\n",
    "    pyplot.figure(1,figsize=(5, 5))    \n",
    "    FPR, TPR, _ = roc_curve(y_true, y_prob)\n",
    "    pyplot.xlim([-0.01, 1.01])\n",
    "    pyplot.ylim([-0.01, 1.01])\n",
    "    pyplot.plot(FPR, TPR, 'r', label='aggregated ROC')\n",
    "    pyplot.xlabel('False Positive Rate')\n",
    "    pyplot.ylabel('True Positive Rate')\n",
    "    pyplot.legend()\n",
    "    pyplot.savefig(\"../_output/rf_fp_1030_agg_auc.svg\", dpi=300)\n",
    "    pyplot.show()\n",
    "    \n",
    "    # calculate the averaged ROC by iterating over the individuals outer predictions\n",
    "    pyplot.figure(0,figsize=(5, 5))\n",
    "    tprs = []\n",
    "    base_fpr = np.linspace(0, 1, 101)\n",
    "    i = 1\n",
    "    for _true, _prob in zip(outer_true,outer_prob):\n",
    "        fpr, tpr, _ = roc_curve(_true, _prob[:, 1])\n",
    "        # alpha means the opacity of the line\n",
    "        pyplot.plot(fpr, tpr, 'r', alpha=0.15,label='%s-th Outer fold' % i)\n",
    "        # interp adjusts the number of datapoints to base_fpr (101)\n",
    "        tpr = interp(base_fpr, fpr, tpr)\n",
    "        # setting the first element of tpr 0 adjusts for a possible artifact of interp()\n",
    "        tpr[0] = 0.0\n",
    "        tprs.append(tpr)\n",
    "        i = i + 1\n",
    "    \n",
    "    # calculate the standard deviation and thereby the upper and lower limits of the averaged ROC\n",
    "    tprs = np.array(tprs)\n",
    "    mean_tprs = tprs.mean(axis=0)\n",
    "    std = tprs.std(axis=0)\n",
    "    tprs_upper = np.minimum(mean_tprs + std, 1)\n",
    "    tprs_lower = mean_tprs - std\n",
    "\n",
    "    # plot the averaged ROC and output the figure to an svg file\n",
    "    pyplot.plot(base_fpr, mean_tprs, 'r', label='avr. ROC')\n",
    "    pyplot.fill_between(base_fpr, tprs_lower, tprs_upper, color='grey', alpha=0.3, label='STD+-')\n",
    "    pyplot.xlim([-0.01, 1.01])\n",
    "    pyplot.ylim([-0.01, 1.01])\n",
    "    pyplot.xlabel('False Positive Rate')\n",
    "    pyplot.ylabel('True Positive Rate')\n",
    "    pyplot.axes().set_aspect('equal', 'datalim')\n",
    "    pyplot.title('Averaged AUC-ROC')\n",
    "    pyplot.legend()\n",
    "    pyplot.savefig(\"../_output/rf_fp_1030_avr_auc.svg\", dpi=300)\n",
    "    pyplot.show()\n",
    "    \n",
    "    # write the aforementioned metrics into a file\n",
    "    f = open(\"../_output/rf_fp_1030_analysis.txt\",\"w+\")\n",
    "    f.write(str(conf_matrix)+'\\n')\n",
    "    f.write(classification_report(y_true, y_pred)+'\\n')\n",
    "    f.write('Balanced Accuracy:\\t'+str(balanced_accuracy_score(y_true, y_pred))+'\\n')\n",
    "    f.write('Matthews Coeffici:\\t'+str(matthews_corrcoef(y_true, y_pred))+'\\n')\n",
    "    f.write('Sensitivity:\\t\\t'+str(Sensitivity)+'\\n')\n",
    "    f.write('Specificity:\\t\\t'+str(Specificity)+'\\n')\n",
    "    f.write('AUC-ROC:\\t\\t'+str(AUC_base_model)+'\\n')\n",
    "    f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_training(inner_true,inner_pred,inner_prob):\n",
    "    \n",
    "    # print statement and list elements are appended into single arrays for convenience\n",
    "    print(\"Evaluation of the Training Set:\\n\")\n",
    "    training_true = np.hstack(inner_true)\n",
    "    training_pred = np.hstack(inner_pred)\n",
    "    training_prob = np.vstack(inner_prob)\n",
    "\n",
    "\n",
    "    # confusion matrix is printed using built in functions\n",
    "    conf_matrix = confusion_matrix(training_true, training_pred)\n",
    "    print(conf_matrix)\n",
    "\n",
    "\n",
    "    # calculate and print the ROC from the aggregated (i.e. stacked) inner predictions and plot the graph\n",
    "    pyplot.figure(3,figsize=(5, 5))\n",
    "    FPR, TPR, _ = roc_curve(training_true, training_prob[:,1])\n",
    "    pyplot.plot(FPR, TPR, 'b', label='Base Model')\n",
    "    pyplot.xlim([-0.01, 1.01])\n",
    "    pyplot.ylim([-0.01, 1.01])\n",
    "    pyplot.xlabel('False Positive Rate')\n",
    "    pyplot.ylabel('True Positive Rate')\n",
    "    pyplot.title('K-Fold-aggregated AUC-ROC')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()\n",
    "\n",
    "    # calculate the averaged ROC by iterating over the individuals inner predictions\n",
    "    tprs = []\n",
    "    base_fpr = np.linspace(0, 1, 101)\n",
    "    pyplot.figure(2,figsize=(5, 5))\n",
    "    i = 1\n",
    "    for _true, _prob in zip(inner_true,inner_prob):\n",
    "        fpr, tpr, _ = roc_curve(_true, _prob[:, 1])\n",
    "        pyplot.plot(fpr, tpr, 'b', alpha=0.15, label='%s-th outer Fold' % i)\n",
    "        tpr = interp(base_fpr, fpr, tpr)\n",
    "        tpr[0] = 0.0\n",
    "        tprs.append(tpr)\n",
    "        i = i + 1\n",
    "\n",
    "    # calculate the standard deviation and thereby the upper and lower limits of the averaged ROC\n",
    "    tprs = np.array(tprs)\n",
    "    mean_tprs = tprs.mean(axis=0)\n",
    "    std = tprs.std(axis=0)\n",
    "    tprs_upper = np.minimum(mean_tprs + std, 1)\n",
    "    tprs_lower = mean_tprs - std\n",
    "\n",
    "    # plot the averaged ROC and output the figure to an svg file\n",
    "    pyplot.plot(base_fpr, mean_tprs, 'b', label='avr. ROC')\n",
    "    pyplot.fill_between(base_fpr, tprs_lower, tprs_upper, color='grey', alpha=0.3, label='STD+-')\n",
    "    pyplot.xlim([-0.01, 1.01])\n",
    "    pyplot.ylim([-0.01, 1.01])\n",
    "    pyplot.xlabel('False Positive Rate')\n",
    "    pyplot.ylabel('True Positive Rate')\n",
    "    pyplot.axes().set_aspect('equal', 'datalim')\n",
    "    pyplot.title('Averaged AUC-ROC')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataframe into RAM\n",
    "df = pd.read_csv('../../03-GenerateFingerprints/_output/fp_1030.csv')\n",
    "\n",
    "# Assign meta_cols which happen to be the first 10 columns and input cols (the rest of the cols)\n",
    "meta_cols = df.columns[:10]\n",
    "input_cols = df.columns[10:]\n",
    "\n",
    "X = np.array(df.loc[:,input_cols])\n",
    "df['PUBCHEM_ACTIVITY_OUTCOME'] = df['PUBCHEM_ACTIVITY_OUTCOME'].astype('category').cat.codes\n",
    "y = df['PUBCHEM_ACTIVITY_OUTCOME'].values\n",
    "\n",
    "# get the number of samples of actives and inactives of the assay\n",
    "N_1 = df.PUBCHEM_ACTIVITY_OUTCOME.value_counts().to_list()[0]\n",
    "N_2 = df.PUBCHEM_ACTIVITY_OUTCOME.value_counts().to_list()[1]\n",
    "\n",
    "# calculate the relative amount of the minority class to majority class for input in the SMOTE function\n",
    "sampling_prsnt = round(np.exp(-abs(math.log(N_1/N_2))),2)\n",
    "sampling_smote = 2 * sampling_prsnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer split method:\tStratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b567f7c332bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m                       }\n\u001b[1;32m     46\u001b[0m     \u001b[0mrand_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHalvingRandomSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distributions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_candidates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mrand_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_innerCV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_innerCV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best sets of parameters:\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrand_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/luis/anaconda3/envs/my-rdkit-env/lib/python3.7/site-packages/sklearn/model_selection/_search_successive_halving.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_samples_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# Set best_score_: BaseSearchCV does not set it, as refit is a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/luis/anaconda3/envs/my-rdkit-env/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/luis/anaconda3/envs/my-rdkit-env/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/luis/anaconda3/envs/my-rdkit-env/lib/python3.7/site-packages/sklearn/model_selection/_search_successive_halving.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             results = evaluate_candidates(candidate_params, cv,\n\u001b[0;32m--> 320\u001b[0;31m                                           more_results=more_results)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mn_candidates_to_keep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_candidates\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/luis/anaconda3/envs/my-rdkit-env/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    807\u001b[0m                                    (split_idx, (train, test)) in product(\n\u001b[1;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                                    enumerate(cv.split(X, y, groups))))\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/luis/anaconda3/envs/my-rdkit-env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/luis/anaconda3/envs/my-rdkit-env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/luis/anaconda3/envs/my-rdkit-env/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/luis/anaconda3/envs/my-rdkit-env/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/luis/anaconda3/envs/my-rdkit-env/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# define lists to append the model outputs to\n",
    "outer_pred = []\n",
    "outer_true = []\n",
    "outer_prob = []\n",
    "\n",
    "inner_pred = []\n",
    "inner_true = []\n",
    "inner_prob = []\n",
    "\n",
    "# starter outer validation Loop\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "print(\"outer split method:\\t{}\\n\".format(skf))\n",
    "\n",
    "f = open(\"../_output/rf_fp_1030_params.txt\",\"w+\")\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    \n",
    "    # define Datasets, Cross-Validation Metrics and Model-Type\n",
    "    X_innerCV, X_outerCV = X[train_index], X[test_index]\n",
    "    y_innerCV, y_outerCV = y[train_index], y[test_index]\n",
    "    cv = ShuffleSplit(n_splits=5,test_size=0.25, random_state=0)\n",
    "    rf = RandomForestClassifier(n_jobs=-1)\n",
    "    \n",
    "    \n",
    "    # SMOTE-Sampling is used to over sample the minority class and the majority class is undersampled\n",
    "    if (sampling_prsnt < 0.5) & (sampling_smote < 0.75):\n",
    "        over = SMOTE(sampling_strategy=sampling_smote, k_neighbors=30)\n",
    "        under = RandomUnderSampler(sampling_strategy=0.75)\n",
    "        steps = [('o', over), ('u', under)]\n",
    "        pipeline = Pipeline(steps=steps)\n",
    "        X_innerCV, y_innerCV = pipeline.fit_resample(X_innerCV, y_innerCV)\n",
    "    \n",
    "    # Hyperparameter tuning with halvingRandomSearchCV\n",
    "    p_grid = {\n",
    "            'max_depth': [randint(10,20)],\n",
    "            'max_features': [randint(40,50)],\n",
    "            'min_samples_leaf': [5,6,7,8,9,10,11,12,13],\n",
    "            'min_samples_split': [4,5,6,7,8,9,10,11,12,13],\n",
    "            'n_estimators':[100, 200, 300, 400, 500],\n",
    "            'bootstrap': [False,True],\n",
    "            'oob_score': [False],\n",
    "            'random_state': [42],\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'n_jobs': [-1],\n",
    "            'class_weight' : [None, 'balanced']\n",
    "                      }\n",
    "    rand_search = HalvingRandomSearchCV(estimator=rf, param_distributions=p_grid, factor=3, random_state=42, n_jobs=-1, verbose=0, cv=cv, n_candidates=500)\n",
    "    rand_search.fit(X_innerCV, y_innerCV)\n",
    "    # write the best models into a file\n",
    "    f.write(\"best sets of parameters:\\n{}\\n\".format(rand_search.best_params_))\n",
    "    \n",
    "    \n",
    "    # use the best estimator and fit it to the DS it was trained on and then predict the DS for outer validation\n",
    "    clf = rand_search.best_estimator_\n",
    "    clf.fit(X_innerCV,y_innerCV)\n",
    "    \n",
    "    # predict inner Cross-Validation set to checm overfitting\n",
    "    y_inner_pred = clf.predict(X_innerCV).flatten()\n",
    "    y_inner_prob = clf.predict_proba(X_innerCV)#[:,1]\n",
    "    \n",
    "    # predict outer Cross-Validation set to check for the model performance on unseen data\n",
    "    y_pred = clf.predict(X_outerCV).flatten()\n",
    "    y_prob = clf.predict_proba(X_outerCV)#[:,1]\n",
    "    \n",
    "    \n",
    "    # append the inner predictions and the true values to the output-lists\n",
    "    inner_true.append(y_innerCV)\n",
    "    inner_pred.append(y_inner_pred)\n",
    "    inner_prob.append(y_inner_prob)\n",
    "\n",
    "    # append the outer predictions and the true values to the output-lists\n",
    "    outer_true.append(y_outerCV)\n",
    "    outer_pred.append(y_pred)\n",
    "    outer_prob.append(y_prob)\n",
    "    \n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "# evaluate the model und the training phase\n",
    "evaluate_training(inner_true,inner_pred,inner_prob)\n",
    "evaluate_model(outer_true,outer_pred,outer_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quellen:\n",
    "- https://stats.stackexchange.com/questions/186337/average-roc-for-repeated-10-fold-cross-validation-with-probability-estimates\n",
    "- https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "- http://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html\n",
    "- https://machinelearningmastery.com/nested-cross-validation-for-machine-learning-with-python/\n",
    "- https://www.google.com/search?q=nested+cross+validation+sklearn&oq=nested+cross+validation+sklearn&aqs=chrome..69i57j0i22i30l5.17640j1j9&sourceid=chrome&ie=UTF-8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
