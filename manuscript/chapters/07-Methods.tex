\chapter{Methods}\label{sec:methods}
In the following sections, the computational process is described. The implementation, including the data sets, will be available at \url{https://github.com/Foly93/masterthesis}. For programming, either Python or Bash was used. Jupyter notebooks were used as a user interface for python programming. Furthermore, python scripts and bash scripts were used as well.
%
%
\section{Descriptors - CP and ECFPs}\label{sec:ecfppubchem}
As inputs for the \ac{rfc} two different descriptors are chose. The first descriptor are the morphological information that are extracted from the \acl{rid} of the \ac{cp} assay of Bray \textit{et al.}\cite{Bray2017}. Before the \acl{rid} can be inputted they need to be preprocessed, which is described in detail in \fref{sec:prepro}. The baseline descriptors that \ac{cp} data has to compete with are \acp{ecfp}. For all compounds present in the final data sets (referred to as \aclp{cmrds}) the structural identifier was computed from the canonical \ac{smiles} utilizing the \texttt{Chem} package from the \texttt{RDkit} python library.\cite{Landrum2019} The obtained compound identifiers are \num{2048}-bit vectors with radius \num{2}. Every bit in this vector is considered a feature for the machine learning algorithm.\cite{Landrum2019}\\
First, the \ac{cp} features and \ac{ecfp} features are used separately as inputs. Afterwards, selected features from both features spaces are used as input together.
%
%
\section{Targets}\label{sec:targets}
For creating annotations for the input vectors, the \acl{p} bioassay database was queried. \acl{p} comprises more than \num{1200000} bioassays.\cite{Pubchem2021}The amount of information stored at the \acl{p} database is so vast that the process of finding data sets fitting for this project is a problem on its own. A stepwise filtering process was created to find relevant bioassays.\\
First, the eleven biggest folders are downloaded from the \acl{p} database, each containing up to \num{1000} bioassays.\cite{PubchemDB2021} Then the \num{100} assays with the most compounds are kept from each of the eleven folders resulting in \num{1100} bioassay data sets with large size. The next step was to find assays with an endpoint related to toxicity or cell morphology. For that purpose, two auxiliary files are generated. The first file was downloaded directly from \url{https://pubchem.ncbi.nlm.nih.gov/} and contains detailed information about each of the \num{1100} assays. That includes the \ac{aid}, the assay name and a description of the assay and the endpoint tested. The second file is a list of protein targets enriched for cytotoxic and cytostatic phenotypes generated by Mervin \textit{et al.}\cite{Mervin2016} A program searches the assay information file for instances from the protein targets list. It saves the \ac{aid}s that are related to said targets to another list. The resulting list of supposedly cytotoxic compounds consists of \num{671} assays. The compound overlap with the raw image data needs to be found (see \fref{sec:rid}). However, the compounds are annotated with their \acl{p} assigned \ac{cid} which is not a widely used identifier. Therefore a more general identifier was required for each compound that can be used to screen against the \ac{cp} data set. The \acl{p} website offers functionality that generates a description for a list of \ac{cid}s. Part of that description is the \ac{inchik}, which is a much more general, unique identifier that can be translated into other identifiers like \ac{smiles} strings. Therefore the next step was to concatenate all compounds into a list and upload it to the \acl{p} website. Afterwards, the description of the \ac{cid}s was then downloaded. The \ac{cid}s in the \num{671} bioassays are then exchanged for the \ac{inchik}s. The compound overlap with the \ac{cp} compounds was conducted using the \acl{mbs} (which turned out to be suboptimal in \fref{sec:prepro} and had to be corrected). Therefore, each assay's compounds were merged with the \ac{inchik} annotations of the \ac{cp} data set and only entries present in both data sets are kept. Next the \ac{inchik}s are exchanged for their \acl{mbs} identifiers.\\
Not all \num{671} assays were further investigated. As mentioned in \fref{sec:pubchem}, \acl{p} labels their compounds 'active', 'inactive' 'unspecified' or 'inconclusive'. If a dataset contains no actives or too little, machine learning applications will have trouble correctly categorising the data since the two classes (active and inactive class) are too imbalanced. Thus, in the next step, the threshold of at least \num{100} active compounds was applied as a filter, resulting in \num{52} bioassays. From these \num{52} bioassays, 'inconclusive' and 'unspecified' rated compounds were deleted. Notice that \num{100} active compounds can be a comparably small amount of actives since some of the \num{52} final bioassays have more than \num{20000} compounds in total.\\
Conclusively, \num{52} spreadsheets were obtained, containing the metadata broad sample as a molecular identifier and the PubChem activity outcome as a label for classification.
%
%
\section{Preprocessing}\label{sec:prepro}
As mentioned in \fref{sec:rid}, the raw image data contains meta and data columns. The metadata columns of the \ac{cp} data dictate the decision-making process during the preprocessing, and the data columns themselves are the subject of preprocessing. The data columns or \ac{cp} features vectors are the inputs for machine learning applications described in the following chapters.\\
In brief, the preprocessing combined the bioassay data set and the raw image data into \num{52} fully annotated and \ac{ml}-ready data sets. Eventually, they contain information about the features, about the endpoint and some metadata information, e.g. for compound identification.\\
During the preprocessing, the \acl{mbs} turned out to be a suboptimal identifier because it is not unique for every compound (see \fref{sec:rid}). Different \acl{mbs} values are used for the same compound if it corresponds to a different compound concentration or plate. Therefore, the \acl{mbs} was exchanged for the canonical \ac{smiles} string.\\
First, the individual \num{384}-well plates were centred on the mock samples. For that purpose, the plate-wise average of the untreated samples was calculated for every morphological feature and then subtracted from the treated samples. The next step was to calculate compound-concentration-wise medians of each feature. However, some compounds appear in multiple concentrations. Therefore, a new metadata column was introduced that labelled each row either as a \acl{scc} or a multi-concentration-compound. The \aclp{scc}' medians were computed in a straight forward fashion for the whole raw image data set, whereas the multi-concentration-compounds are not yet processed. The resulting \acl{prid} frame has \num{31692} rows and \num{1768} feature vectors.\\
Next the \acl{prid} was merged with each of the \num{52} bioassays by keeping \acl{mbs} identifiers which are present in both data sets. Next, the compounds were properly annotated by transferring the \acl{mbs} into the canonical \ac{smiles} string. The canonical \ac{smiles} were computed from python's \texttt{sklearn} library. Afterwards, the multi-concentration-compounds, present in the combined data frames, were inspected since they required further consideration. The \ac{ml} algorithm requires one morphological profile per compound and one label per compound. Thus, for each multi-concentration-compound, the feature medians were computed only for the most frequent concentration. The other concentrations were discarded. This computational process results in \num{52} \aclp{cmrds} with \num{1768} relevant features and varying row number since the compound wise overlap varies from assay to assay. A table of the resulting 52 assays with the number of active, inactive and total compounds can be found in \fref{tab:assayoverview}.
\begin{table}[H]
	\centering
	\caption[Overview over the Combined Machine Learning Ready Data Sets]{This table gives an overview over the \aclp{cmrds} obtained from the preprocessing procedure. The \ac{aid} from the original \acl{p} data set is given and the number of active, inactive and total compounds. All \num{52} assays combined have \num{371978} inactive labels and \num{12140} active lables.}
	\label{tab:assayoverview}
	\begin{tabularx}{\textwidth}{lllXllll}
		\toprule
		AID & Inactives & Actives & Total & AID & Inactives & Actives & Total\\
		\midrule
		1030 & 4804 & 832 & 5636 & 588334 & 6978 & 133 & 7111 \\
		1458 & 6547 & 487 & 7034 & 588458 & 8850 & 117 & 8967 \\
		1529 & 7794 & 150 & 7944 & 588852 & 8840 & 128 & 8968 \\
		1531 & 7818 & 122 & 7940 & 588855 & 7536 & 151 & 7687 \\
		1578 & 7816 & 146 & 7962 & 602340 & 21297 & 102 & 21399 \\
		1688 & 6814 & 158 & 6972 & 624202 & 8342 & 237 & 8579 \\
		1822 & 7822 & 141 & 7963 & 624256 & 8574 & 139 & 8713 \\
		2098 & 7719 & 132 & 7851 & 624296 & 6475 & 439 & 6914 \\
		2156 & 7868 & 149 & 8017 & 624297 & 7440 & 252 & 7692 \\
		2216 & 7328 & 154 & 7482 & 624466 & 8844 & 173 & 9017 \\
		2330 & 1752 & 131 & 1883 & 651610 & 18234 & 218 & 18452 \\
		2540 & 8015 & 127 & 8142 & 651635 & 8036 & 125 & 8161 \\
		2553 & 7908 & 109 & 8017 & 651658 & 18839 & 163 & 19002 \\
		2599 & 7913 & 229 & 8142 & 651744 & 297 & 207 & 504 \\
		2642 & 7821 & 196 & 8017 & 720504 & 8197 & 341 & 8538 \\
		2796 & 7837 & 345 & 8182 & 720532 & 1164 & 185 & 1349 \\
		485270 & 7992 & 190 & 8182 & 720582 & 8933 & 121 & 9054 \\
		485313 & 7497 & 491 & 7988 & 720635 & 248 & 126 & 374 \\
		485314 & 7589 & 172 & 7761 & 720648 & 8928 & 126 & 9054 \\
		504333 & 6598 & 526 & 7124 & 743012 & 315 & 195 & 510 \\
		504444 & 5296 & 275 & 5571 & 743014 & 315 & 188 & 503 \\
		504466 & 6909 & 260 & 7169 & 743015 & 320 & 211 & 531 \\
		504582 & 8022 & 110 & 8132 & 777 & 2831 & 911 & 3742 \\
		504652 & 7829 & 312 & 8141 & 894 & 4769 & 324 & 5093 \\
		504660 & 8094 & 131 & 8225 & 932 & 6399 & 420 & 6819 \\
		504847 & 9047 & 175 & 9222 & 938 & 2528 & 158 & 2686 \\
		\bottomrule
	\end{tabularx}
\end{table}\noindent
%
%
\section{Feature Engineering}\label{sec:features}
The feature engineering for \ac{cp} descriptors was performed using three methods further described in \fref{sec:featimport}. Firstly, the \ac{pca} is performed using the \ac{pca} method available from \texttt{sklearn}.\cite{Pedregosa2012} The method was applied to the \ac{cp}-\acl{p} data sets to find the features that comprise most of the variance. The \num{100} features that account for most of the variance in the first principal component were added to the list of most important features.\\
The next step was to pick important features by using a \ac{rfc} algorithm with \acl{gi}. However, before the \acl{gi} feature importance can be applied, redundancy of similar features had to be reduced. For that reason, features were clustered based on their Spearman correlation with all other features. A distance cut-off was applied that resulted in \num{400} remaining clusters. From each cluster, one feature was picked at random. The resulting \num{400} presumably non-redundant features entered the random forest-based feature selection algorithm. This \ac{rfc} used \num{250} estimators from which the features were scored using the \acl{gi} to select the \num{100} most important ones (see \fref{eq:giniimpforest}).\cite{scikitfeature2021}\\
The last method used \ac{mrmr} to extract the thirty most important features based on a maximum-relevance-minimum-redundancy criterion. The computational python implementation from Peng \textit{et al.}\cite{Peng2005} was used (\url{https://pypi.org/project/pymrmr/}).\\
Since the \acp{ecfp} are boolean features (either \num{0} or \num{1}) Spearman-clustering, and \ac{mrmr} will not work. Therefore, only the random forest feature importance of \texttt{sklearn} was used to score the structural fingerprint features. Instead of only using the \acl{gi}, the entropy-based feature selection was utilized as well. This resulted in \num{200} most important features from the \num{2048} features present in the original fingerprint data set for each of the \num{52} \aclp{cmrds}.\cite{scikitfeature2021}\\
In the next step, the most important \ac{cp} and \ac{ecfp} features are combined into one set of features for each of the \num{52} assays. The top features lists obtained from \ac{mrmr}, \ac{pca} and \ac{gi} can contain a small overlap. Therefore, the top \ac{cp} features from each list are combined into one list, and duplicate features are removed. The same is done for the \ac{ecfp} features. Finally, both descriptors' best features were combined and labelled by the \acl{p} bioassays.
%
%
\section{Prediction}\label{sec:randomforest}
For each endpoint represented by a \acl{p} assay, an \ac{rfc} was developed and trained. Four different modelling cycles can be distinguished. Every cycle used the labels from \acl{p} assays as targets. The first cycle was solely concerned with the \ac{cp} descriptors, the second cycle was concerned with the \acp{ecfp}, whilst the third cycle used the feature engineered, combined set of descriptors. The last run omits feature engineering and incorporates all features from both descriptor sets.\\
Nested \num{5}-Fold \ac{cv} was used to train the model and tune the hyperparameters with a stratified split strategy. For the inner loop that fitted the parameter of the \ac{rfc}, a random split strategy was used with \num{5}-fold \ac{cv} (see \fref{sec:cv}). Before splitting the data in the inner loop, \ac{smote} was applied to increase the minority class label by \SI{100}{\percent} effectively doubling its size, and random undersampling was applied as well (see \fref{sec:smote}). The minority class amounted to \SI{75}{\percent} compared to the majority class label after applying this sampling strategy. \ac{smote} was not applied to the held-out test set of the outer loop. Thus, the model was validated with real data points only.\\
The hyperparameters are optimized using a halving random search method from \texttt{sklearn}.\cite{Bergstra2012,Pedregosa2012} For that purpose a parameter grid was used for each inner \ac{cv} iteration. The parameters which were covered can be seen in \fref{tab:hyperparametergrid}. 
\begin{table}[H]
	\centering
	\caption[Hyperparameters covered by the \ac{rfc}]{Hyperparameters covered by the \ac{rfc}}
	\label{tab:hyperparametergrid}
	\begin{tabularx}{0.75\textwidth}{ll}
		\toprule
		Hyperparameter & Values Covered\\
		\midrule
		max\_depth& 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20\\
		max\_features& 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50\\
		min\_samples\_leaf& 5, 6, 7, 8, 9, 10, 11, 12, 13\\
		min\_samples\_split& 4, 5, 6, 7, 8, 9, 10, 11, 12, 13\\
		n\_estimators& 100, 200, 300, 400, 500\\
		bootstrap& False, True\\
		oob\_score& False\\
		criterion& gini, entropy\\
		class\_weight& None, balanced\\
		\bottomrule
	\end{tabularx}
\end{table}\noindent
From this parameter grid \num{500} combinations were randomly sampled for each inner \ac{cv} iteration and only the best estimator was returned and evaluated in the outer \ac{cv} iteration. Since a \num{5}-fold \ac{cv} was in use, five best estimators are evaluated in total by calculating the \ac{ba}, \ac{mcc}, \ac{tpr}, \ac{tnr}, \ac{roc} and \ac{auc}.\\
This procedure is conducted for each of the \num{52} \acl{cmrds}. Afterwards, the \acp{ecfp} are generated and modelled in the same way. The feature engineered combination of both is used as descriptors, followed by the fourth modelling cycle that used the entire feature space. 